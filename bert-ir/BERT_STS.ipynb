{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.spacy_based_ir import SpacyIR\n",
    "from models.bert_sts import BertSTSIR\n",
    "from models.bert_nli import BertNLIIR\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT STSIR Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/19/2019 18:06:24 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /home/pbanerj6/.pytorch_pretrained_bert/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "04/19/2019 18:06:30 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at /home/pbanerj6/.pytorch_pretrained_bert/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "04/19/2019 18:06:30 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/pbanerj6/.pytorch_pretrained_bert/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmpy8e2cxud\n",
      "04/19/2019 18:06:41 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irmodel = BertSTSIR(topk=50,output_dir=\"/scratch/pbanerj6/stsb_output\",model=\"pytorch_model.bin.4\",eval_batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Bert Examples:: 100%|██████████| 1/1 [00:00<00:00, 5599.87it/s]\n",
      "Tokenizing:: 0it [00:00, ?it/s]04/19/2019 18:10:11 - INFO - models.bert_sts -   *** Example ***\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -   guid: id1:0\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -   tokens: [CLS] i like doing research [SEP] i like doing research [SEP]\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -   input_ids: 101 178 1176 1833 1844 102 178 1176 1833 1844 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -   label: 0 (id = 0)\n",
      "Tokenizing:: 1it [00:00, 330.08it/s]\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -   ***** Running evaluation *****\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -     Num examples = 1\n",
      "04/19/2019 18:10:11 - INFO - models.bert_sts -     Batch size = 1024\n",
      "Scoring:: 100%|██████████| 1/1 [00:00<00:00, 25.85it/s]\n",
      "Finding TopK:: 100%|██████████| 1/1 [00:00<00:00, 6384.02it/s]\n",
      "Writing to File:: 100%|██████████| 1/1 [00:00<00:00, 3738.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\"data\":{\"id1\":\"i like doing research\"}, \"facts\":[\"i like doing research\"]}\n",
    "irmodel.predict(data,\"./output.json\",\"./sample_token.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
