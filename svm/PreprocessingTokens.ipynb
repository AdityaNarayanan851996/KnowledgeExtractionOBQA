{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import time\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cls(fname):\n",
    "    return np.array(pickle.load(open(fname,\"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/scratch/pbanerj6/sml-dataset/\"\n",
    "trainSamples = 75000\n",
    "n_iter = 1000\n",
    "n_trainSamples = [100,500,1000,10000,20000,50000,75000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens = load_cls(path+\"X_train_tokens.p\")[:trainSamples]\n",
    "X_val_tokens = load_cls(path+\"X_val_tokens.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def my_preprocessor(doc):\n",
    "    return doc\n",
    "\n",
    "# tokenize the doc and lemmatize its tokens\n",
    "def my_tokenizer(doc):\n",
    "    return doc\n",
    "\n",
    "custom_vec = CountVectorizer(preprocessor=my_preprocessor, tokenizer=my_tokenizer)\n",
    "cwm = custom_vec.fit_transform(X_train_tokens)\n",
    "tokens = custom_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = Pipeline([\n",
    "('vect',  CountVectorizer(min_df=.0025, max_df=0.25, ngram_range=(1,3),preprocessor=my_preprocessor, tokenizer=my_tokenizer)),\n",
    "('tfidf', TfidfTransformer()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline.fit(X_train_tokens)\n",
    "X_train_f = feature_pipeline.transform(X_train_tokens)\n",
    "X_val_f =feature_pipeline.transform(X_val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 4946)\n",
      "(15000, 4946)\n",
      "  (0, 4841)\t0.10206178659166008\n",
      "  (0, 4839)\t0.08624482478591163\n",
      "  (0, 4821)\t0.06371831378366755\n",
      "  (0, 4780)\t0.06366358851627836\n",
      "  (0, 4663)\t0.07830016022291594\n",
      "  (0, 4417)\t0.08273504970397311\n",
      "  (0, 4134)\t0.11562298798481806\n",
      "  (0, 4133)\t0.07335159088280982\n",
      "  (0, 4132)\t0.06920039631052462\n",
      "  (0, 4104)\t0.3273389450898796\n",
      "  (0, 4087)\t0.11764227401664118\n",
      "  (0, 4085)\t0.1509260023017018\n",
      "  (0, 4057)\t0.0908128063327985\n",
      "  (0, 4015)\t0.11094850496752785\n",
      "  (0, 3714)\t0.09210674833984055\n",
      "  (0, 3666)\t0.10784207232155846\n",
      "  (0, 3400)\t0.07876395120926866\n",
      "  (0, 3373)\t0.11863612012376877\n",
      "  (0, 3349)\t0.0601734977821298\n",
      "  (0, 3294)\t0.0958211573526837\n",
      "  (0, 3293)\t0.08823113123682577\n",
      "  (0, 3249)\t0.2365493977005762\n",
      "  (0, 3091)\t0.08512195700569382\n",
      "  (0, 3088)\t0.1257127077833879\n",
      "  (0, 2932)\t0.10989535928014282\n",
      "  :\t:\n",
      "  (74999, 3790)\t0.17714484668441033\n",
      "  (74999, 3788)\t0.18712346156584975\n",
      "  (74999, 3787)\t0.1798206498666181\n",
      "  (74999, 3711)\t0.16115672956038768\n",
      "  (74999, 3540)\t0.19826641550010793\n",
      "  (74999, 3539)\t0.12056623418889197\n",
      "  (74999, 3213)\t0.19256686904852954\n",
      "  (74999, 3088)\t0.10829472964861432\n",
      "  (74999, 3024)\t0.20209613814516014\n",
      "  (74999, 2821)\t0.08016103978985319\n",
      "  (74999, 2275)\t0.20209613814516014\n",
      "  (74999, 2103)\t0.19206005054746444\n",
      "  (74999, 1915)\t0.18641985843633058\n",
      "  (74999, 1631)\t0.17352770435026943\n",
      "  (74999, 1523)\t0.16828065767636985\n",
      "  (74999, 1454)\t0.11725023502987372\n",
      "  (74999, 1390)\t0.17417096344340424\n",
      "  (74999, 1389)\t0.17856039534825888\n",
      "  (74999, 1032)\t0.101373029253951\n",
      "  (74999, 1031)\t0.08654932959431853\n",
      "  (74999, 1023)\t0.10543967249370405\n",
      "  (74999, 589)\t0.11038573154503561\n",
      "  (74999, 517)\t0.36364585473491134\n",
      "  (74999, 441)\t0.20304383822500036\n",
      "  (74999, 440)\t0.16372909586120352\n"
     ]
    }
   ],
   "source": [
    "print (X_train_f.shape)\n",
    "print (X_val_f.shape)\n",
    "print (X_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
