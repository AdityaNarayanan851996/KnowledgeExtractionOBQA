{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf = Pipeline([\n",
    "('vect', CountVectorizer()),\n",
    "('tfidf', TfidfTransformer()),\n",
    "('clf', MultinomialNB()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "predicted = text_clf.predict(docs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348868175765646"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "     categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbanerj6/.conda/envs/allen8/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9127829560585885"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),\n",
    " ])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.87       319\n",
      "         comp.graphics       0.88      0.97      0.92       389\n",
      "               sci.med       0.94      0.90      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "             micro avg       0.91      0.91      0.91      1502\n",
      "             macro avg       0.92      0.91      0.91      1502\n",
      "          weighted avg       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258,  11,  15,  35],\n",
       "       [  4, 379,   3,   3],\n",
       "       [  5,  33, 355,   3],\n",
       "       [  5,  10,   4, 379]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "     'tfidf__use_idf': (True, False),\n",
    "     'clf__alpha': (1e-2, 1e-3),\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, iid=False, n_jobs=-1,verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  40 | elapsed:    2.6s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  40 | elapsed:    2.8s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  40 | elapsed:    3.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    3.3s finished\n",
      "/home/pbanerj6/.conda/envs/allen8/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9151349867929058"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 13:47:26 - WARNING - allennlp.common.file_utils -   Deprecated cache directory found (/home/pbanerj6/.allennlp/datasets).  Please remove this directory from your system to free up space.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertConfig, BertModel\n",
    "\n",
    "from allennlp.common.testing import ModelTestCase\n",
    "from allennlp.data.dataset import Batch\n",
    "from allennlp.data.fields import TextField, ListField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers.wordpiece_indexer import PretrainedBertIndexer\n",
    "from allennlp.data.tokenizers import WordTokenizer\n",
    "from allennlp.data.tokenizers.word_splitter import BertBasicWordSplitter\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.modules.token_embedders.bert_token_embedder import BertEmbedder\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self):\n",
    "      self.token_indexer = PretrainedBertIndexer(pretrained_model=\"bert-base-cased\")\n",
    "      self.bert_model = BertModel.from_pretrained(pretrained_model_name=\"bert-base-cased\")\n",
    "      self.token_embedder = BertEmbedder(self.bert_model,top_layer_only=True)\n",
    "      self.tokenizer = WordTokenizer(word_splitter=BertBasicWordSplitter())\n",
    "      self.device= \"cuda:1\"\n",
    "      self.token_embedder.to(self.device)\n",
    "    def fit(self, X, y):\n",
    "      return self\n",
    "\n",
    "    def softmax(self,x):\n",
    "      e_x = np.exp(x - np.max(x))\n",
    "      return e_x / e_x.sum()\n",
    "\n",
    "    def transform(self, X):\n",
    "      listofembedds = []\n",
    "      batchinstances = [] \n",
    "      vocab = Vocabulary()\n",
    "      listofbatches = []\n",
    "      for sentence1 in tqdm(X,desc=\"Tokenizing:\"):\n",
    "        tokens1 = self.tokenizer.tokenize(sentence1)\n",
    "        instance1 = Instance({\"tokens\": TextField(tokens1, {\"bert\": self.token_indexer})})\n",
    "        batchinstances.append(instance1)\n",
    "        if len(batchinstances)>5:\n",
    "            listofbatches.append(Batch(batchinstances))\n",
    "            batchinstances=[]\n",
    "      listofbatches.append(Batch(batchinstances))\n",
    "      for batch in tqdm(listofbatches,\"Generatin Embedding:\"): \n",
    "          batch.index_instances(vocab)\n",
    "          padding_lengths = batch.get_padding_lengths()\n",
    "          tensor_dict = batch.as_tensor_dict(padding_lengths)\n",
    "          tokens = tensor_dict[\"tokens\"]\n",
    "          bert_vectors1 = self.token_embedder(Variable(tokens[\"bert\"]).to(self.device), offsets=Variable(tokens[\"bert-offsets\"]).to(self.device))\n",
    "          bert_vectors1 = bert_vectors1.detach().cpu().numpy()\n",
    "          tokens[\"bert\"].to(\"cpu\")\n",
    "          tokens[\"bert-offsets\"].to(\"cpu\")\n",
    "          for vectors in bert_vectors1:\n",
    "            mean = np.mean(vectors,axis=0)\n",
    "            #print(mean)\n",
    "            arr = self.softmax(mean)\n",
    "            listofembedds.append(arr)\n",
    "      return np.array(listofembedds)\n",
    "\n",
    "\n",
    "import logging\n",
    "from torch.multiprocessing import Manager, Process, Queue, get_logger\n",
    "logger = get_logger()  # pylint: disable=invalid-name\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/29/2019 13:47:33 - ERROR - allennlp.data.token_indexers.wordpiece_indexer -   Your BERT model appears to be cased, but your indexer is lowercasing tokens.\n",
      "01/29/2019 13:47:34 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/pbanerj6/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "01/29/2019 13:47:34 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at /home/pbanerj6/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "01/29/2019 13:47:34 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/pbanerj6/.pytorch_pretrained_bert/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir /tmp/tmp2o59ptf3\n",
      "01/29/2019 13:47:38 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Tokenizing:: 100%|██████████| 2257/2257 [00:12<00:00, 220.88it/s]\n",
      "Generatin Embedding:: 100%|██████████| 377/377 [00:32<00:00, 12.91it/s]\n",
      "/home/pbanerj6/.conda/envs/allen8/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('fec', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('tfidf', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max...dom_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "tfidf = Pipeline([('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer())])\n",
    "featureunion = FeatureUnion([(\"tfidf\",tfidf),(\"mec\",MeanEmbeddingVectorizer())])\n",
    "\n",
    "text_clf = Pipeline([\n",
    "     (\"fec\",featureunion),\n",
    "     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),\n",
    " ])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing:: 100%|██████████| 1502/1502 [00:08<00:00, 171.76it/s]\n",
      "Generatin Embedding:: 100%|██████████| 251/251 [00:22<00:00, 11.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9141145139813582"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.88       319\n",
      "         comp.graphics       0.88      0.98      0.93       389\n",
      "               sci.med       0.94      0.89      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "             micro avg       0.91      0.91      0.91      1502\n",
      "             macro avg       0.92      0.91      0.91      1502\n",
      "          weighted avg       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -2,  0,  1],\n",
       "       [ 0,  2, -1, -1],\n",
       "       [ 0,  1, -1,  0],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target, predicted)-np.array([[258,  11,  15,  35],\n",
    "       [  4, 379,   3,   3],\n",
    "       [  5,  33, 355,   3],\n",
    "       [  5,  10,   4, 379]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
